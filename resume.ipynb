{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pinecone\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Pinecone as PC\n",
    "# Cell 1: Import necessary libraries\n",
    "import PyPDF2\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import pinecone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key_resume = os.getenv(\"PINECONE_API_KEY_RESUME\")\n",
    "api_key_jd = os.getenv(\"PINECONE_API_KEY_JD\")\n",
    "GROQ_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume API Key: pcsk_4CEtRb_EYiumo4ypRb3j4oeEVneiLZWa8ZkYg87Ty83LxhfvunoBjDk6yPa3WuWz47PSHK\n",
      "Job Description API Key: pcsk_7W6gTn_URecqxiU2F4gWmLUsLEozTRqAk97jZ6f5xvknevuRqkwik6LATcyA1tCCTncbN1\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "print(f\"Resume API Key: {api_key_resume}\")\n",
    "print(f\"Job Description API Key: {api_key_jd}\")\n",
    "print(GROQ_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull('nomic-embed-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"resume\", glob=\"./*.pdf\", loader_cls=PyPDFLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "document=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'resume\\\\ac_cv.pdf', 'page': 0}, page_content='Amogh Chavan\\nData Scientist, Machine Learning Engineer and Front End Developer\\n♂¶obile+91 7030790097 auuchavan@gmail.com /h⌢mePanvel, Navi Mumbai\\n/linkedinin/amogh-chavan-21-coder//githubgithub.com/ac-coder-21 X x.com/accode21\\nProfile\\nAs a passionate Machine Learning enthusiast, I possess a comprehensive understanding of various machine learning\\nalgorithms, adept at both implementing them using popular libraries like Scikit-learn and TensorFlow, and building them\\nfrom scratch. Furthermore, my proficiency in Data Visualization tools such as Matplotlib, Seaborn and Plotly allows me\\nto create compelling visualizations that uncover actionable insights from complex datasets. With these skills, I tackle\\ndiverse data challenges, from modeling to analysis and clear presentation for informed decision-making.\\nAreas of Expertise\\nPython - Flask - Django - Machine Learning - EDA - Data Analysis - Data Visualization - SQL - MongoDB - JavaScript -\\nR - ReactJS - Angular - PHP - HTML - CSS\\nProfessional Experience\\nMachine Learning Intern, (MindCraft Software Pvt. Ltd) Andheri, Mumbai 06/2023 - 07/2023\\n• Developed Project for predicting whether the customer is eligible for applying insurance for the car.\\n• Conducted EDA on the dataset and compared classification models to select the most optimal one.\\nData Science and Machine Learning Intern (YBI Foundation) Remote 08/2023 - 10/2023\\n• Learned about various machine learning algorithms.\\n• Carried out various tasks and implemented it in the form of project.\\nData Science Intern, (Code Clause) Remote 12/2023 - 1/2024\\n• Implemented machine Learning algorithms in 3 projects.\\n• Received Letter of Recommendation for exceptional performance during internship tenure\\nProjects\\n• Drowsiness Detection Web Application.\\n• Chat-Bot using NLP.\\n• Insurance Validation Prediction.\\n• Result Analysis Application.\\n• VidSense - A chrome extension for extracting video summary.\\n• Bandhu - A mental health companion.\\nEducation\\nB.E. in Computer Engineering Lokmanya Tilak College of Engineering CGPA: 9.14 2021-2024\\nDiploma in Computer Engineering A.C. Patil College of Engineering Percentage: 92.11% 2021-2019\\nSoft Skills\\n• Team Player • Good Communication • Learn New Things • Multiple Languages\\n[EHMG]'),\n",
       " Document(metadata={'source': 'resume\\\\AIML_JD.pdf', 'page': 0}, page_content='Job Title: AI/ML Entry-Level Engineer \\nLocation: Remote / On-Site / Hybrid \\nCompany: [Your Company Name] \\nType: Full-Time \\nAbout Us: \\n[Your Company Name] specializes in developing AI and Machine Learning solutions to \\naddress complex challenges. Join our team to contribute to innovative projects and grow \\nyour expertise in a dynamic environment. \\nResponsibilities: \\n• Assist in developing, training, and deploying machine learning models. \\n• Preprocess and analyze datasets for model training. \\n• Support model evaluation and optimization tasks. \\n• Collaborate with cross-functional teams to integrate AI solutions. \\n• Document workflows and experiment results. \\nQualifications: \\n• Bachelor’s degree in Computer Science, AI, Data Science, or related field. \\n• Basic understanding of machine learning algorithms and concepts. \\n• Proficiency in Python and ML libraries (e.g., TensorFlow, PyTorch). \\n• Strong analytical and problem-solving skills. \\nPreferred Skills: \\n• Familiarity with cloud platforms (AWS, GCP). \\n• Exposure to version control systems (e.g., Git). \\nBenefits: \\n• Competitive salary. \\n• Flexible work options. \\n• Opportunities for growth and professional development. \\n '),\n",
       " Document(metadata={'source': 'resume\\\\ng_cv.pdf', 'page': 0}, page_content='NISHANT GAWDE\\n+91 9284883121 ⋄ Navi Mumbai, Maharashtra\\nLinkedIn ⋄ gawdenishant1@gmail.com ⋄ Github\\nOBJECTIVE\\nDriven entry-level candidate seeking a role in Generative AI and related areas where I can utilize my understanding\\nof machine learning and programming skills in Python. Excited to contribute to groundbreaking projects, deepen my\\nknowledge of AI technologies, and excel in a dynamic, collaborative setting that promotes development and learning.\\nEDUCATION\\nBachelor of Engineering, Mumbai University CGPI: 8.38\\nHSC, Dnyanpushpa Vidya Niketan and Junior College 67%\\nSSC, Bhonsala Military School Nashik 80%\\nSKILLS\\nTechnical Skills Python, Machine Learning, HTML, CSS, C/C++\\nStrengths Team Player, Adaptability, Time Management, Team Management, Leadership\\nVersion Control Git, Github\\nCERTIFICATIONS\\nFoundational Generative AI\\niNeuron - Certificate\\n• Gained in-depth understanding of generative models such as Generative Adversarial Networks (GANs) and\\nVariational Autoencoders (VAEs).\\n• Leveraged the open-source model Llama 3.1 for content creation and utilized Pinecone and ChromaDB for\\neffective storage and retrieval of high-dimensional data in generative AI applications.\\nChatGPT Prompt Engineering for Developers\\nOpenAI - Certificate\\n• Mastered effective prompt engineering techniques to optimize interactions and improve AI-generated outputs\\nacross various use cases.\\n• Applied advanced prompting strategies, such as few-shot learning and iterative refinement, to enhance model\\nperformance.\\nPROJECTS\\nVoice Assistant for Visually ImpairedCreated a voice assistant using YOLOv8 to identify and vocalize nearby\\nobjects and Indian currency. Features include playing songs, telling jokes, and opening files via voice commands,\\nwith enhanced accuracy through machine learning algorithms.\\nHealSage HealSage is a medical chatbot powered by the LLama 3.1 70B model via the Groq API. It delivers real-time\\nmedical advice by integrating Nomic text embeddings with Ollama and Pinecone for efficient data management.\\nMCQ Generator Powered by Llama 3.1 70B via the Groq API, it creates high-quality multiple-choice questions\\nfrom your data. Perfect for educators and quiz creators, it turns user-provided information into precise, customizable\\nquestions with ease.\\nEXTRA-CURRICULAR ACTIVITIES\\n• Qualified for the state swimming championships and ranked 20th in the National Open Sea Swimming Cham-\\npionship, showcasing strong competitive swimming skills and endurance.\\n• Donated blood on personal level to hospitals many times and even participated in blood donation campaigns.'),\n",
       " Document(metadata={'source': 'resume\\\\pr_cv.pdf', 'page': 0}, page_content='PRATIK SHALGAR\\n+91 9326540475 | Navi Mumbai, India | pratik.shalgar@gmail.com | LinkedIn | Portfolio\\nSKILLS\\n• Data Analysis: Python, SQL • Programming Languages: Python, SQL\\n• Data Visualization: Power BI • Database Management: MySQL\\nEXPERIENCE\\nData Analyst Intern Oct 2023 - Nov 2023\\nCodSoft Navi Mumbai, India\\n• Analyzed large datasets with Pandas and NumPy, achieving a 30% improvement in decision-making.\\n• Utilized Matplotlib to effectively visualize data insights, resulting in a 25% reduction in report generation time.\\nPROJECTS\\nCoffee Shop Sales Analysis Link\\nSQL | Power BI | Data Visualization | Trend Analysis\\n• Analyzed sales data using SQL to identify trends, boosting revenue by 20%.\\n• Developed Power BI dashboards, providing real-time insights on sales performance.\\n• Streamlined reporting processes, reducing data analysis time by 40%.\\nData Job Insights Explorer: SQL-Driven Career Analysis Link\\nSQL | Data | Analysis | ETL\\n• Enhanced relevancy in job recommendations by identifying top skills, increasing accuracy by 85%.\\n• Analyzed over 5,000 job listings to extract key trends in data-related professions and remote work opportunities.\\n• Optimized salary insights, enabling precise benchmarks for candidates, improving negotiation outcomes by 70%.\\nSafeSiteAccess Link\\nPython | OpenCV | CNNs | YOLO\\n• Designed PPE kit detection and facial recognition, achieving 100% safety compliance.\\n• Automated attendance recording, reducing manual errors by 90%.\\n• Improved efficiency, cutting entry time by 50% and boosting productivity.\\nEDUCATION\\nBachelor of Science in Computer Engineering , University of Mumbai Aug 2020 - May 2024\\nBharati Vidyapeeth College of Engineering, Navi Mumbai, CGPA: 09.00\\nCERTIFICATIONS\\nChatGPT Prompt Engineering for Developers Link\\n• Acquired advanced prompt engineering skills to optimize interactions and enhance AI-generated outcomes across\\nvarious applications.\\n• Learned and applied advanced prompting techniques, including few-shot learning and iterative refinement, to\\nimprove model performance.\\nTata Data Visualisation: Empowering Business with Effective Insights Job Simulation on Forage Link\\n• Completed a simulation involving creating data visualizations for Tata Consultancy Services.\\n• Created visuals for data analysis to help executives with effective decision making.\\nAccenture North America Data Analytics and Visualization Job Simulation on Forage Link\\n• Completed a simulation focused on advising a hypothetical social media client as a Data Analyst at Accenture.\\n• Cleaned, modeled, and analyzed 7 datasets to uncover insights into content trends to inform strategic decisions.'),\n",
       " Document(metadata={'source': 'resume\\\\WEB_JD.pdf', 'page': 0}, page_content='Job Title: Entry-Level Web Developer \\nLocation: Remote / On-Site / Hybrid \\nCompany: [Your Company Name] \\nType: Full-Time \\nAbout Us: \\n[Your Company Name] builds user-friendly and scalable web solutions. Join us to develop \\nengaging digital experiences and enhance your technical skills. \\nResponsibilities: \\n• Assist in developing and maintaining websites and web applications. \\n• Collaborate with designers to implement UI/UX designs. \\n• Write clean, efficient, and well-documented code. \\n• Troubleshoot and resolve technical issues. \\n• Stay updated with web development best practices. \\nQualifications: \\n• Bachelor’s degree in Computer Science, Web Development, or related field. \\n• Proficiency in HTML, CSS, and JavaScript. \\n• Familiarity with frameworks (e.g., React, Angular). \\n• Basic understanding of backend technologies (e.g., Node.js). \\nPreferred Skills: \\n• Knowledge of version control systems (e.g., Git). \\n• Exposure to CMS platforms (e.g., WordPress). \\nBenefits: \\n• Competitive salary. \\n• Flexible work environment. \\n• Professional development opportunities. \\n ')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'resume\\\\ac_cv.pdf', 'page': 0}, page_content='Amogh Chavan\\nData Scientist, Machine Learning Engineer and Front End Developer\\n♂¶obile+91 7030790097 auuchavan@gmail.com /h⌢mePanvel, Navi Mumbai\\n/linkedinin/amogh-chavan-21-coder//githubgithub.com/ac-coder-21 X x.com/accode21\\nProfile\\nAs a passionate Machine Learning enthusiast, I possess a comprehensive understanding of various machine learning\\nalgorithms, adept at both implementing them using popular libraries like Scikit-learn and TensorFlow, and building them\\nfrom scratch. Furthermore, my proficiency in Data Visualization tools such as Matplotlib, Seaborn and Plotly allows me\\nto create compelling visualizations that uncover actionable insights from complex datasets. With these skills, I tackle\\ndiverse data challenges, from modeling to analysis and clear presentation for informed decision-making.\\nAreas of Expertise\\nPython - Flask - Django - Machine Learning - EDA - Data Analysis - Data Visualization - SQL - MongoDB - JavaScript -\\nR - ReactJS - Angular - PHP - HTML - CSS'),\n",
       " Document(metadata={'source': 'resume\\\\ac_cv.pdf', 'page': 0}, page_content='R - ReactJS - Angular - PHP - HTML - CSS\\nProfessional Experience\\nMachine Learning Intern, (MindCraft Software Pvt. Ltd) Andheri, Mumbai 06/2023 - 07/2023\\n• Developed Project for predicting whether the customer is eligible for applying insurance for the car.\\n• Conducted EDA on the dataset and compared classification models to select the most optimal one.\\nData Science and Machine Learning Intern (YBI Foundation) Remote 08/2023 - 10/2023\\n• Learned about various machine learning algorithms.\\n• Carried out various tasks and implemented it in the form of project.\\nData Science Intern, (Code Clause) Remote 12/2023 - 1/2024\\n• Implemented machine Learning algorithms in 3 projects.\\n• Received Letter of Recommendation for exceptional performance during internship tenure\\nProjects\\n• Drowsiness Detection Web Application.\\n• Chat-Bot using NLP.\\n• Insurance Validation Prediction.\\n• Result Analysis Application.\\n• VidSense - A chrome extension for extracting video summary.'),\n",
       " Document(metadata={'source': 'resume\\\\ac_cv.pdf', 'page': 0}, page_content='• Result Analysis Application.\\n• VidSense - A chrome extension for extracting video summary.\\n• Bandhu - A mental health companion.\\nEducation\\nB.E. in Computer Engineering Lokmanya Tilak College of Engineering CGPA: 9.14 2021-2024\\nDiploma in Computer Engineering A.C. Patil College of Engineering Percentage: 92.11% 2021-2019\\nSoft Skills\\n• Team Player • Good Communication • Learn New Things • Multiple Languages\\n[EHMG]'),\n",
       " Document(metadata={'source': 'resume\\\\AIML_JD.pdf', 'page': 0}, page_content='Job Title: AI/ML Entry-Level Engineer \\nLocation: Remote / On-Site / Hybrid \\nCompany: [Your Company Name] \\nType: Full-Time \\nAbout Us: \\n[Your Company Name] specializes in developing AI and Machine Learning solutions to \\naddress complex challenges. Join our team to contribute to innovative projects and grow \\nyour expertise in a dynamic environment. \\nResponsibilities: \\n• Assist in developing, training, and deploying machine learning models. \\n• Preprocess and analyze datasets for model training. \\n• Support model evaluation and optimization tasks. \\n• Collaborate with cross-functional teams to integrate AI solutions. \\n• Document workflows and experiment results. \\nQualifications: \\n• Bachelor’s degree in Computer Science, AI, Data Science, or related field. \\n• Basic understanding of machine learning algorithms and concepts. \\n• Proficiency in Python and ML libraries (e.g., TensorFlow, PyTorch). \\n• Strong analytical and problem-solving skills. \\nPreferred Skills:'),\n",
       " Document(metadata={'source': 'resume\\\\AIML_JD.pdf', 'page': 0}, page_content='• Strong analytical and problem-solving skills. \\nPreferred Skills: \\n• Familiarity with cloud platforms (AWS, GCP). \\n• Exposure to version control systems (e.g., Git). \\nBenefits: \\n• Competitive salary. \\n• Flexible work options. \\n• Opportunities for growth and professional development.'),\n",
       " Document(metadata={'source': 'resume\\\\ng_cv.pdf', 'page': 0}, page_content='NISHANT GAWDE\\n+91 9284883121 ⋄ Navi Mumbai, Maharashtra\\nLinkedIn ⋄ gawdenishant1@gmail.com ⋄ Github\\nOBJECTIVE\\nDriven entry-level candidate seeking a role in Generative AI and related areas where I can utilize my understanding\\nof machine learning and programming skills in Python. Excited to contribute to groundbreaking projects, deepen my\\nknowledge of AI technologies, and excel in a dynamic, collaborative setting that promotes development and learning.\\nEDUCATION\\nBachelor of Engineering, Mumbai University CGPI: 8.38\\nHSC, Dnyanpushpa Vidya Niketan and Junior College 67%\\nSSC, Bhonsala Military School Nashik 80%\\nSKILLS\\nTechnical Skills Python, Machine Learning, HTML, CSS, C/C++\\nStrengths Team Player, Adaptability, Time Management, Team Management, Leadership\\nVersion Control Git, Github\\nCERTIFICATIONS\\nFoundational Generative AI\\niNeuron - Certificate\\n• Gained in-depth understanding of generative models such as Generative Adversarial Networks (GANs) and\\nVariational Autoencoders (VAEs).'),\n",
       " Document(metadata={'source': 'resume\\\\ng_cv.pdf', 'page': 0}, page_content='Variational Autoencoders (VAEs).\\n• Leveraged the open-source model Llama 3.1 for content creation and utilized Pinecone and ChromaDB for\\neffective storage and retrieval of high-dimensional data in generative AI applications.\\nChatGPT Prompt Engineering for Developers\\nOpenAI - Certificate\\n• Mastered effective prompt engineering techniques to optimize interactions and improve AI-generated outputs\\nacross various use cases.\\n• Applied advanced prompting strategies, such as few-shot learning and iterative refinement, to enhance model\\nperformance.\\nPROJECTS\\nVoice Assistant for Visually ImpairedCreated a voice assistant using YOLOv8 to identify and vocalize nearby\\nobjects and Indian currency. Features include playing songs, telling jokes, and opening files via voice commands,\\nwith enhanced accuracy through machine learning algorithms.\\nHealSage HealSage is a medical chatbot powered by the LLama 3.1 70B model via the Groq API. It delivers real-time'),\n",
       " Document(metadata={'source': 'resume\\\\ng_cv.pdf', 'page': 0}, page_content='medical advice by integrating Nomic text embeddings with Ollama and Pinecone for efficient data management.\\nMCQ Generator Powered by Llama 3.1 70B via the Groq API, it creates high-quality multiple-choice questions\\nfrom your data. Perfect for educators and quiz creators, it turns user-provided information into precise, customizable\\nquestions with ease.\\nEXTRA-CURRICULAR ACTIVITIES\\n• Qualified for the state swimming championships and ranked 20th in the National Open Sea Swimming Cham-\\npionship, showcasing strong competitive swimming skills and endurance.\\n• Donated blood on personal level to hospitals many times and even participated in blood donation campaigns.'),\n",
       " Document(metadata={'source': 'resume\\\\pr_cv.pdf', 'page': 0}, page_content='PRATIK SHALGAR\\n+91 9326540475 | Navi Mumbai, India | pratik.shalgar@gmail.com | LinkedIn | Portfolio\\nSKILLS\\n• Data Analysis: Python, SQL • Programming Languages: Python, SQL\\n• Data Visualization: Power BI • Database Management: MySQL\\nEXPERIENCE\\nData Analyst Intern Oct 2023 - Nov 2023\\nCodSoft Navi Mumbai, India\\n• Analyzed large datasets with Pandas and NumPy, achieving a 30% improvement in decision-making.\\n• Utilized Matplotlib to effectively visualize data insights, resulting in a 25% reduction in report generation time.\\nPROJECTS\\nCoffee Shop Sales Analysis Link\\nSQL | Power BI | Data Visualization | Trend Analysis\\n• Analyzed sales data using SQL to identify trends, boosting revenue by 20%.\\n• Developed Power BI dashboards, providing real-time insights on sales performance.\\n• Streamlined reporting processes, reducing data analysis time by 40%.\\nData Job Insights Explorer: SQL-Driven Career Analysis Link\\nSQL | Data | Analysis | ETL'),\n",
       " Document(metadata={'source': 'resume\\\\pr_cv.pdf', 'page': 0}, page_content='Data Job Insights Explorer: SQL-Driven Career Analysis Link\\nSQL | Data | Analysis | ETL\\n• Enhanced relevancy in job recommendations by identifying top skills, increasing accuracy by 85%.\\n• Analyzed over 5,000 job listings to extract key trends in data-related professions and remote work opportunities.\\n• Optimized salary insights, enabling precise benchmarks for candidates, improving negotiation outcomes by 70%.\\nSafeSiteAccess Link\\nPython | OpenCV | CNNs | YOLO\\n• Designed PPE kit detection and facial recognition, achieving 100% safety compliance.\\n• Automated attendance recording, reducing manual errors by 90%.\\n• Improved efficiency, cutting entry time by 50% and boosting productivity.\\nEDUCATION\\nBachelor of Science in Computer Engineering , University of Mumbai Aug 2020 - May 2024\\nBharati Vidyapeeth College of Engineering, Navi Mumbai, CGPA: 09.00\\nCERTIFICATIONS\\nChatGPT Prompt Engineering for Developers Link'),\n",
       " Document(metadata={'source': 'resume\\\\pr_cv.pdf', 'page': 0}, page_content='CERTIFICATIONS\\nChatGPT Prompt Engineering for Developers Link\\n• Acquired advanced prompt engineering skills to optimize interactions and enhance AI-generated outcomes across\\nvarious applications.\\n• Learned and applied advanced prompting techniques, including few-shot learning and iterative refinement, to\\nimprove model performance.\\nTata Data Visualisation: Empowering Business with Effective Insights Job Simulation on Forage Link\\n• Completed a simulation involving creating data visualizations for Tata Consultancy Services.\\n• Created visuals for data analysis to help executives with effective decision making.\\nAccenture North America Data Analytics and Visualization Job Simulation on Forage Link\\n• Completed a simulation focused on advising a hypothetical social media client as a Data Analyst at Accenture.\\n• Cleaned, modeled, and analyzed 7 datasets to uncover insights into content trends to inform strategic decisions.'),\n",
       " Document(metadata={'source': 'resume\\\\WEB_JD.pdf', 'page': 0}, page_content='Job Title: Entry-Level Web Developer \\nLocation: Remote / On-Site / Hybrid \\nCompany: [Your Company Name] \\nType: Full-Time \\nAbout Us: \\n[Your Company Name] builds user-friendly and scalable web solutions. Join us to develop \\nengaging digital experiences and enhance your technical skills. \\nResponsibilities: \\n• Assist in developing and maintaining websites and web applications. \\n• Collaborate with designers to implement UI/UX designs. \\n• Write clean, efficient, and well-documented code. \\n• Troubleshoot and resolve technical issues. \\n• Stay updated with web development best practices. \\nQualifications: \\n• Bachelor’s degree in Computer Science, Web Development, or related field. \\n• Proficiency in HTML, CSS, and JavaScript. \\n• Familiarity with frameworks (e.g., React, Angular). \\n• Basic understanding of backend technologies (e.g., Node.js). \\nPreferred Skills: \\n• Knowledge of version control systems (e.g., Git). \\n• Exposure to CMS platforms (e.g., WordPress). \\nBenefits: \\n• Competitive salary.'),\n",
       " Document(metadata={'source': 'resume\\\\WEB_JD.pdf', 'page': 0}, page_content='• Exposure to CMS platforms (e.g., WordPress). \\nBenefits: \\n• Competitive salary. \\n• Flexible work environment. \\n• Professional development opportunities.')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding.embed_query(\"How are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from pinecone import Pinecone\n",
    "\n",
    "   # Initialize Pinecone client\n",
    "pc_resume = Pinecone(api_key=api_key_resume)\n",
    "pc_jd = Pinecone(api_key=api_key_jd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pinecone.control.pinecone.Pinecone object at 0x00000133C69B1450>\n"
     ]
    }
   ],
   "source": [
    "print(pc_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"resume-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "PineconeConfigurationError",
     "evalue": "You haven't specified an Api-Key.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPineconeConfigurationError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m \u001b[43mPC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CODING\\Project\\Lib\\site-packages\\langchain_community\\vectorstores\\pinecone.py:432\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    404\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Pinecone:\n\u001b[0;32m    405\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m    DEPRECATED: use langchain_pinecone.PineconeVectorStore.from_texts instead:\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m    Construct Pinecone wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03m            )\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 432\u001b[0m     pinecone_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pinecone_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     pinecone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    435\u001b[0m     pinecone\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[0;32m    436\u001b[0m         texts,\n\u001b[0;32m    437\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(upsert_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[0;32m    443\u001b[0m     )\n",
      "File \u001b[1;32md:\\CODING\\Project\\Lib\\site-packages\\langchain_community\\vectorstores\\pinecone.py:362\u001b[0m, in \u001b[0;36mPinecone.get_pinecone_index\u001b[1;34m(cls, index_name, pool_threads)\u001b[0m\n\u001b[0;32m    359\u001b[0m pinecone \u001b[38;5;241m=\u001b[39m _import_pinecone()\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pinecone_v3():\n\u001b[1;32m--> 362\u001b[0m     pinecone_instance \u001b[38;5;241m=\u001b[39m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPinecone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPINECONE_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_threads\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m pinecone_instance\u001b[38;5;241m.\u001b[39mlist_indexes()\n\u001b[0;32m    366\u001b[0m     index_names \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indexes\u001b[38;5;241m.\u001b[39mindex_list[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexes\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[1;32md:\\CODING\\Project\\Lib\\site-packages\\pinecone\\control\\pinecone.py:199\u001b[0m, in \u001b[0;36mPinecone.__init__\u001b[1;34m(self, api_key, host, proxy_url, proxy_headers, ssl_ca_certs, ssl_verify, config, additional_headers, pool_threads, index_api, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m \u001b[43mPineconeConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_ca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_ca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_verify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_verify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenapi_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing openapi_config is no longer supported. Please pass settings such as proxy_url, proxy_headers, ssl_ca_certs, and ssl_verify directly to the Pinecone constructor as keyword arguments. See the README at https://github.com/pinecone-io/pinecone-python-client for examples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     )\n",
      "File \u001b[1;32md:\\CODING\\Project\\Lib\\site-packages\\pinecone\\config\\pinecone_config.py:34\u001b[0m, in \u001b[0;36mPineconeConfig.build\u001b[1;34m(api_key, host, additional_headers, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     32\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIgnoring PINECONE_ADDITIONAL_HEADERS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConfigBuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CODING\\Project\\Lib\\site-packages\\pinecone\\config\\config.py:56\u001b[0m, in \u001b[0;36mConfigBuilder.build\u001b[1;34m(api_key, host, proxy_url, proxy_headers, ssl_ca_certs, ssl_verify, additional_headers, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m source_tag \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(SOURCE_TAG, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified an Api-Key.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified a host.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mPineconeConfigurationError\u001b[0m: You haven't specified an Api-Key."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "docsearch = PC.from_texts([t.page_content for t in text_chunks], embedding, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='Description\\nAllergies are among the most common of medical\\ndisorders. It is estimated that 60 million Americans, ormore than one in every five people, suffer from someform of allergy, with similar proportions throughoutmuch of the rest of the world. Allergy is the single largestreason for school absence and is a major source of lostproductivity in the workplace.\\nAn allergy is a type of immune reaction. Normally,'), Document(page_content='Description\\nAllergies are among the most common of medical\\ndisorders. It is estimated that 60 million Americans, ormore than one in every five people, suffer from someform of allergy, with similar proportions throughoutmuch of the rest of the world. Allergy is the single largestreason for school absence and is a major source of lostproductivity in the workplace.\\nAn allergy is a type of immune reaction. Normally,'), Document(page_content='Allergen —A substance that provokes an allergic\\nresponse.\\nAllergic rhinitis —Inflammation of the mucous\\nmembranes of the nose and eyes in response to anallergen.\\nAnaphylaxis —Increased sensitivity caused by previ-\\nous exposure to an allergen that can result in bloodvessel dilation and smooth muscle contraction.Anaphylaxis can result in sharp blood pressuredrops and difficulty breathing.\\nAngioedema —Severe non-inflammatory swelling of')]\n"
     ]
    }
   ],
   "source": [
    "query = \"What are Allergies\"\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_kwargs={'k':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "    Use the following pieces of information to answer the user's question.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "\n",
    "    Only return the helpful answer below and nothing else.\n",
    "    Helpful answer:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(temperature=0.5, groq_api_key=GROQ_KEY, model_name=\"llama-3.1-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\Foundations of Gen AI\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Allergy is a reaction of the immune system.\n",
      "Answer: Acne is a common skin disease characterized by pimples on the face, chest, and back. It occurs when the pores of the skin become clogged with oil, dead skin cells, and bacteria.\n",
      "Answer: Bile duct cancer, also known as cholangiocarcinoma, is a malignant tumor of the bile ducts within the liver (intrahepatic) or leading from the liver to the small intestine (extrahepatic).\n",
      "Answer: Bile duct cancer, also known as cholangiocarcinoma, is a malignant tumor of the bile ducts within the liver (intrahepatic) or leading from the liver to the small intestine (extrahepatic).\n",
      "Exiting\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\Foundations of Gen AI\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "while True:\n",
    "  user_input = input(f\"Input Prompt: \")\n",
    "  if user_input == 'exit':\n",
    "    print('Exiting')\n",
    "    sys.exit()\n",
    "  if user_input == '':\n",
    "    continue\n",
    "  result = qa.invoke({'query': user_input})\n",
    "  print(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
